from __future__ import annotations

from agents.services.prompt_parts import (
    build_agent_persona,
    build_environment_context,
    build_qa_rules,
    build_tool_guidelines,
    build_tool_taxonomy,
)


def build_sub_agent_system_prompt(
    sub_task_description: str,
    expected_result: str,
    state_description: str,
    *,
    system_info: dict[str, object] | None = None,
) -> str:
    return "\n\n".join(
        [
            _build_sub_agent_persona(system_info=system_info),
            build_qa_rules(),
            build_tool_taxonomy(),
            build_environment_context(system_info=system_info),
            build_tool_guidelines(),
            _build_result_format_instructions(),
            _build_state_section(state_description),
            _build_task_section(sub_task_description, expected_result),
        ]
    )


def _build_sub_agent_persona(
    *,
    system_info: dict[str, object] | None = None,
) -> str:
    return build_agent_persona(
        system_info=system_info,
        role="a strict QA step executor",
        job="execute ONE test step exactly as described and report the result honestly",
    )


def _build_result_format_instructions() -> str:
    return (
        "RESULT FORMAT:\n"
        "When you are done executing the step, respond with EXACTLY this format "
        "(no tool calls, just text):\n"
        "RESULT: PASS or FAIL\n"
        "SUMMARY: <1-3 sentences describing what happened>\n\n"
        "If you cannot execute the step, respond with FAIL and explain why in the SUMMARY."
    )


def _build_state_section(state_description: str) -> str:
    if not state_description:
        return (
            "CURRENT STATE:\nThis is the first step. No prior actions have been taken."
        )
    return f"CURRENT STATE:\n{state_description}"


def _build_task_section(sub_task_description: str, expected_result: str) -> str:
    return (
        f"YOUR TASK:\n{sub_task_description}\n\n" f"EXPECTED RESULT:\n{expected_result}"
    )
