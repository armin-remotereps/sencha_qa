# Live Command Output Streaming

## Description

When the AI agent executes shell commands on the remote machine (e.g., `pip install`, `apt-get`, build scripts), the user currently sees nothing until the command completes entirely. The stdout/stderr then appears as a single wall of text in the `[Tool Result]` log entry.

We need to stream command output line-by-line in real-time so users can watch commands execute live on the test run case detail page.

## Current Behavior

1. Agent calls `execute_command` tool with a shell command
2. `controller_run_command` dispatches to the controller client via WebSocket
3. Controller client runs `subprocess.run()` (blocking, captures all output at once)
4. Controller sends back a single `command_result` message with full stdout/stderr
5. Server receives result, agent loop logs `[Tool Result] stdout...` as one block
6. User sees nothing during execution, then gets everything at once

## Desired Behavior

1. Agent calls `execute_command` tool with a shell command
2. Server dispatches `run_command` to the controller client (same as before)
3. Controller client runs `subprocess.Popen()` with line-by-line stdout/stderr reading
4. Controller sends incremental `command_output` messages back through WebSocket as lines are produced
5. Server receives each `command_output` line and broadcasts it via the existing `on_log` callback (which persists to DB + streams to frontend WebSocket)
6. Controller sends final `command_result` when the process exits (same as before)
7. User sees each line of output appear in real-time in the logs panel

## Requirements

### Controller Client (executor.py + protocol.py + client.py)

- New `MessageType.COMMAND_OUTPUT` for incremental output lines
- New `CommandOutputPayload` dataclass with fields: `stream` (stdout/stderr), `line` (the text)
- `execute_command` replaced with a new `execute_command_streamed` that uses `subprocess.Popen` + line-by-line reading
- The streamed executor accepts an `on_output` callback for each line
- `_handle_run_command` in client.py sends `command_output` messages for each line, then the final `command_result`
- Background commands (`&`) keep existing behavior (no streaming needed)

### Server - Controller Consumer (controller_consumer.py + controller_reply_tracker.py)

- Handle new `command_output` message type from the controller
- Forward `command_output` to the reply channel (similar to how `command_result` is forwarded)

### Server - Services (projects/services.py)

- New `controller_run_command_streamed()` that:
  - Dispatches the command to the controller (same as before)
  - Loops receiving on the reply channel, handling `command_output` lines by calling the `on_log` callback
  - Returns the final `CommandResult` when `command_result` arrives
- Accepts an `on_log: Callable[[str], None] | None` parameter for streaming output lines

### Agent Tool Layer (agents/services/tools_controller.py + tool_registry.py)

- `execute_command` tool accepts an `on_log` callback via `ToolContext`
- Calls `controller_run_command_streamed` instead of `controller_run_command`
- Each output line is forwarded via `on_log` with a `[Command] ` prefix for distinction

### Frontend (test_run_case_detail.html)

- `[Command]` prefixed lines rendered with distinct styling (monospace green for stdout, red for stderr prefix)
- No structural changes needed â€” existing `log` WebSocket message type and auto-scroll already work

## Non-Requirements

- No new WebSocket consumer needed (reuses existing `TestRunCaseConsumer`)
- No new DB model needed (logs append to existing `pivot.logs` TextField)
- No changes to the test run list/detail pages
- No changes to upload flow

## Verification

- Logic tester: Run a test with a long-running command (e.g., `sleep 1 && echo line1 && sleep 1 && echo line2`) and verify lines appear incrementally
- Nightmare tester: Verify the live log display on the test run case detail page shows streaming output
- Uncle bob: Clean code review
